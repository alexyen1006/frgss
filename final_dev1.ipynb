{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexyen1006/frgss/blob/master/final_dev1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjoMtPEoLlnu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# from tensorflow import keras\n",
        "from tensorflow.keras import layers,models,callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e9LYrtfoLpc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LbS_PTCmLln0",
        "outputId": "0ca19a79-c858-40e2-bb71-f9667faf6476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 60, 200, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 58, 198, 32)  896         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 56, 196, 32)  9248        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 56, 196, 32)  128         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 28, 98, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 26, 96, 64)   18496       max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 24, 94, 64)   36928       conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 24, 94, 64)   256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 12, 47, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 47, 128)  73856       max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 10, 45, 128)  147584      conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 10, 45, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 5, 22, 128)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 5, 22, 128)   0           max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 3, 20, 256)   295168      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 3, 20, 256)   1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, 1, 10, 256)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 2560)         0           max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 2560)         0           flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "digit1 (Dense)                  (None, 36)           92196       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit2 (Dense)                  (None, 36)           92196       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit3 (Dense)                  (None, 36)           92196       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit4 (Dense)                  (None, 36)           92196       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit5 (Dense)                  (None, 36)           92196       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit6 (Dense)                  (None, 36)           92196       dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,137,272\n",
            "Trainable params: 1,136,312\n",
            "Non-trainable params: 960\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create CNN Model\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"##不要警告\n",
        "In= Input((60, 200, 3))\n",
        "\n",
        "\n",
        "out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(In)\n",
        "out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "\n",
        "out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "\n",
        "\n",
        "out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "out = Dropout(0.4)(out)\n",
        "\n",
        "out = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "out = Flatten()(out)\n",
        "\n",
        "out = Dropout(0.4)(out)\n",
        "out = [Dense(36, name='digit1', activation='softmax')(out),\n",
        "       Dense(36, name='digit2', activation='softmax')(out),\n",
        "       Dense(36, name='digit3', activation='softmax')(out),\n",
        "       Dense(36, name='digit4', activation='softmax')(out),\n",
        "       Dense(36, name='digit5', activation='softmax')(out),\n",
        "       Dense(36, name='digit6', activation='softmax')(out)]\n",
        "\n",
        "model = Model(inputs=In, outputs=out)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_rIpbCILln3"
      },
      "outputs": [],
      "source": [
        "Char_set = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "\n",
        "def strtoonehot(text):\n",
        "    labellist = []\n",
        "    for letter in text:\n",
        "        onehot = [0 for _ in range(36)]\n",
        "        num = Char_set.find(letter)\n",
        "        onehot[num] = 1\n",
        "        labellist.append(onehot)\n",
        "    return labellist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "YdHeUIghLln4",
        "outputId": "6b0c9d9c-8ed1-4f3f-b4d3-7d261d79860e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading training data...\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "Shape of train data: (10000, 60, 200, 3)\n",
            "Reading validation data...\n",
            "40500\n",
            "41500\n",
            "42500\n",
            "43500\n",
            "44500\n",
            "Shape of validation data: (5000, 60, 200, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Reading training data...\")\n",
        "ans=pd.read_csv('data01_train.csv')\n",
        "ans=ans.set_index('filename')\n",
        "\n",
        "start=30500\n",
        "limit=40500\n",
        "valimit=5000\n",
        "\n",
        "for i in range(start,limit):\n",
        "    if i==start:\n",
        "        nn=[np.array(Image.open(\"data01_train/\" +str(ans.index[i]) ))/255.0]\n",
        "    else:\n",
        "        nn.append(np.array(Image.open(\"data01_train/\" +str(ans.index[i]) ))/255.0)\n",
        "    if i%1000==0:\n",
        "        print(i)\n",
        "train_data=np.stack(nn)\n",
        "\n",
        "read_label = [strtoonehot(ans.iloc[row][0]) for row in range(start,limit)]\n",
        "\n",
        "train_label = [[] for _ in range(6)]\n",
        "for arr in read_label:\n",
        "    for index in range(6):\n",
        "        train_label[index].append(arr[index])\n",
        "train_label = [arr for arr in np.asarray(train_label)]\n",
        "print(\"Shape of train data:\", train_data.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Reading validation data...\")\n",
        "\n",
        "for i in range(limit,limit+valimit):\n",
        "    if (i-limit)==0:\n",
        "        vn=[np.array(Image.open(\"data01_train/\" +str(ans.index[i]) ))/255.0]\n",
        "    else:\n",
        "        vn.append(np.array(Image.open(\"data01_train/\" +str(ans.index[i]) ))/255.0)\n",
        "    if (i-limit)%1000==0:\n",
        "        print(i)\n",
        "vali_data=np.stack(vn)\n",
        "\n",
        "read_label = [strtoonehot(ans.iloc[row][0]) for row in range(limit,valimit+limit)]\n",
        "vali_label = [[] for _ in range(6)]\n",
        "for arr in read_label:\n",
        "    for index in range(6):\n",
        "        vali_label[index].append(arr[index])\n",
        "vali_label = [arr for arr in np.asarray(vali_label)]\n",
        "print(\"Shape of validation data:\", vali_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfVisqQ0Lln5"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = models.load_model('cnn_model_3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jtfbEuFQLln6",
        "outputId": "ebdee263-7c3f-40c8-d67f-97068e83ccba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 5000 samples\n",
            "10000/10000 [==============================] - 115s 11ms/sample - loss: 0.2011 - digit1_loss: 0.0327 - digit2_loss: 0.0272 - digit3_loss: 0.0289 - digit4_loss: 0.0332 - digit5_loss: 0.0394 - digit6_loss: 0.0396 - digit1_acc: 0.9903 - digit2_acc: 0.9914 - digit3_acc: 0.9908 - digit4_acc: 0.9893 - digit5_acc: 0.9878 - digit6_acc: 0.9873 - val_loss: 0.2777 - val_digit1_loss: 0.0403 - val_digit2_loss: 0.0344 - val_digit3_loss: 0.0457 - val_digit4_loss: 0.0403 - val_digit5_loss: 0.0599 - val_digit6_loss: 0.0567 - val_digit1_acc: 0.9884 - val_digit2_acc: 0.9888 - val_digit3_acc: 0.9880 - val_digit4_acc: 0.9868 - val_digit5_acc: 0.9826 - val_digit6_acc: 0.9816\n",
            "Test finished\n"
          ]
        }
      ],
      "source": [
        "# filepath=\"/content/drive/My Drive/Colab Notebooks/cnn_model_3.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_digit6_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "# callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "# model = models.load_model('cnn_model_3.h5')\n",
        "model.fit(train_data, train_label, batch_size=16, epochs=1, verbose=1, validation_data=(vali_data, vali_label))\n",
        "# model.fit(train_data, train_label, batch_size=16, epochs=40, verbose=1, validation_data=(vali_data, vali_label), callbacks=callbacks_list)\n",
        "# model.fit(vali_data, vali_label, batch_size=16, epochs=1, verbose=1, validation_data=(train_data, train_label))\n",
        "\n",
        "# loss, accuracy = model.evaluate(np.array(vali_data), np.array(vali_label), verbose=0)\n",
        "# print('Test loss:', loss)\n",
        "# print('Test accuracy:', accuracy)\n",
        " \n",
        "#model.save('/content/drive/My Drive/Colab Notebooks/cnn_model.h5')\n",
        "print('Test finished')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLuOMn98Lln7"
      },
      "outputs": [],
      "source": [
        "model.save('cnn_model_3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ble-1-tlLln8"
      },
      "outputs": [],
      "source": [
        "model = models.load_model('modelcopy/cnn_model_3yy.h5')\n",
        "loss,b,c,d,e,f,g,h,i,j,k,l,acc = model.evaluate(vali_data, vali_label, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3TBOOCHLln8",
        "outputId": "09bec2f0-df47-4211-91c1-2a1484d48529"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9772"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RaohXQY4Lln9",
        "outputId": "7bc465d7-c3c8-4bdf-e97f-dda4a39d4eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "loading finish!\n",
            "test finished\n",
            "to str\n",
            "finished\n"
          ]
        }
      ],
      "source": [
        "dev_min=0\n",
        "dev_range=10000\n",
        "\n",
        "file_dir='data01_dev/'\n",
        "csv_dir='data01_dev.csv'\n",
        "model_name='modelcopy/cnn_model_3just2.h5'\n",
        "\n",
        "\n",
        "model = models.load_model(model_name)\n",
        "import csv\n",
        "dev=pd.read_csv(csv_dir)\n",
        "dev=dev.set_index('filename')\n",
        "\n",
        "\n",
        "for i in range(dev_min,dev_range):  \n",
        "    if i==dev_min:\n",
        "        nn=[np.array(Image.open(file_dir +str(dev.index[i]) ))/255.0]\n",
        "    else:\n",
        "        nn.append(np.array(Image.open(file_dir +str(dev.index[i]) ))/255.0)\n",
        "    if i%100==0:\n",
        "        print(i)\n",
        "    if i==(dev_range-1):\n",
        "        print('loading finish!')\n",
        "        \n",
        "\n",
        "dev_data=np.stack(nn)\n",
        "\n",
        "\n",
        "\n",
        "prelist=[]\n",
        "\n",
        "predict = model.predict(dev_data, verbose=0)\n",
        "print('test finished')\n",
        "for j in range(0,dev_range-dev_min):  #第幾筆數據\n",
        "    prestr = ''.join([Char_set[np.argmax(predict[i][j], axis=0)] for i in range(0,6)])#第幾個字\n",
        "    prelist.append(prestr)\n",
        "    \n",
        "print('to str')    \n",
        "\n",
        "\n",
        "\n",
        "table = [\n",
        "    ['filename','code']\n",
        "]\n",
        "try:\n",
        "    os.chmod('train.csv',755)\n",
        "    os.chmod('train.csv',(0o070))\n",
        "    os.chmod('train.csv',(0o007))\n",
        "    os.chmod('train.csv',(0o700))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "with open('train.csv', 'a', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    if dev_min==0:\n",
        "        writer.writerows(table)\n",
        "    for i in range(dev_min,dev_range):\n",
        "\n",
        "        table=[[dev.index[i],prelist[i-dev_min]]]\n",
        "        writer.writerows(table)\n",
        "print('finished')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "final_dev1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}